# ğŸ¬ AI-Powered Meeting Video Analysis & Documentation System

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenAI Whisper](https://img.shields.io/badge/OpenAI-Whisper-412991.svg)](https://github.com/openai/whisper)

> **A fully automated Python pipeline that transforms meeting videos into professionally captioned videos with comprehensive documentation reports**

---

## ğŸ“– Table of Contents
- [Overview](#-overview)
- [Key Features](#-key-features)
- [Demo](#-demo)
- [System Architecture](#-system-architecture)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Detailed Usage](#-detailed-usage)
- [Configuration](#%EF%B8%8F-configuration)
- [Output Examples](#-output-examples)
- [Troubleshooting](#-troubleshooting)
- [Performance Metrics](#-performance-metrics)
- [Project Structure](#-project-structure)
- [Technical Stack](#-technical-stack)
- [Roadmap](#-roadmap)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

This project is a **comprehensive solution** for automatically processing meeting videos to generate:
- **Accurately transcribed and timestamped captions**
- **Scene-by-scene visual documentation**
- **Detailed meeting reports with screenshots**
- **Professional captioned videos ready for distribution**

Built for the **AI Intern Screening Test**, this system demonstrates proficiency in computer vision, natural language processing, video processing, and automation engineering.

### ğŸ¬ See It In Action
[ğŸ¥ Watch 3-Minute Demo Video](https://drive.google.com/file/d/14agRRaKQ_oCZ0qTQOqN2mySeMk_7tgNw/view?usp=sharing) | [ğŸ“„ View Sample Report](https://your-sample-report-link.com)

---

## âœ¨ Key Features

### ğŸ¥ **Multi-Source Video Support**
- âœ… **Local Files**: MP4, MOV, AVI formats
- âœ… **YouTube Videos**: Direct URL processing with `yt-dlp`
- âœ… **Cloud Storage**: Google Drive, Dropbox shared links
- âœ… **Web Platforms**: Videos requiring authentication (configurable)

### ğŸ¤– **Advanced AI Processing**
- ğŸ™ï¸ **Speech-to-Text**: OpenAI Whisper (state-of-the-art accuracy)
- ğŸ” **Scene Detection**: SSIM-based algorithm for slide/content changes
- ğŸ‘† **UI Interaction Tracking**: Frame-difference analysis for clicks and transitions
- ğŸ“ **Automatic Summarization**: Segment-wise content analysis

### ğŸ“„ **Professional Documentation**
- ğŸ“Š **Comprehensive Reports**: DOCX/PDF with timestamps, screenshots, and transcripts
- â±ï¸ **Precise Timestamping**: Every scene, interaction, and caption synchronized
- ğŸ–¼ï¸ **Visual Evidence**: Extracted frames at key moments
- ğŸ“‹ **SRT Subtitle Files**: Standard format for universal compatibility

### ğŸ¬ **Video Enhancement**
- ğŸ”¥ **Caption Burning**: Hardcoded subtitles using FFmpeg
- ğŸ¨ **Customizable Styling**: Font, size, color, position
- ğŸ“º **High-Quality Output**: Professional-grade video encoding

### âš¡ **Automation & Usability**
- ğŸš€ **One-Click Processing**: Single command execution
- ğŸ”„ **Progress Tracking**: Real-time status updates
- ğŸ›¡ï¸ **Error Handling**: Robust exception management with detailed logging
- ğŸ’¾ **Organized Outputs**: Structured folder system for all artifacts

---

## ğŸ¥ Demo


### Processing Workflow
<img width="820" height="322" alt="image" src="https://github.com/user-attachments/assets/174ea9a7-4b78-44f7-b9a5-c637881d7e9d" />


https://drive.google.com/file/d/14agRRaKQ_oCZ0qTQOqN2mySeMk_7tgNw/view?usp=sharing

### Sample outputs
<img width="820" height="322" alt="image" src="https://github.com/user-attachments/assets/83dd0ce3-0807-4fd0-9243-36ffaedb4613" />



**ğŸ“¹ Full Demo Video**: https://drive.google.com/file/d/14agRRaKQ_oCZ0qTQOqN2mySeMk_7tgNw/view?usp=sharing

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Video Input   â”‚ (Local/YouTube/Cloud)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Video Download  â”‚ (yt-dlp / Direct)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio Extract   â”‚ (FFmpeg)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transcription  â”‚ (Whisper AI)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scene Detection â”‚ (OpenCV + SSIM)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UI Tracking   â”‚ (Frame Difference)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Report Generate â”‚ (python-docx/ReportLab)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Caption Burning â”‚ (FFmpeg)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Outputs   â”‚ (Video + Report + SRT)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Installation

### Prerequisites
- **Python 3.8 or higher**
- **FFmpeg** (required for video/audio processing)
- **4GB RAM minimum** (8GB recommended for large videos)
- **Internet connection** (for Whisper model download on first run)

### Step 1: Clone the Repository
```bash
git clone https://github.com/kanishgask/AI-Powered-Automated-Video-Analysis-Pipeline.git
cd AI-Powered-Automated-Video-Analysis-Pipeline
```

### Step 2: Install FFmpeg

**Windows:**
```bash
# Using Chocolatey
choco install ffmpeg

# Or download from: https://ffmpeg.org/download.html
# Add to PATH manually
```

**macOS:**
```bash
brew install ffmpeg
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

**Linux (CentOS/RHEL):**
```bash
sudo yum install ffmpeg
```

**Verify Installation:**
```bash
ffmpeg -version
```

### Step 3: Install Python Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: First-Time Setup
On first run, Whisper will automatically download the model (~150MB for base model). This is a one-time process.

---

## ğŸš€ Quick Start

### Basic Usage
```bash
python main.py
```

The program will prompt you for a video source:

```
======================================================================
  Meeting Video Captioning & Documentation Program
======================================================================

Enter video source:
  - Local file path (e.g., C:\Videos\meeting.mp4)
  - YouTube URL (e.g., https://www.youtube.com/watch?v=...)
  - Cloud storage link (Google Drive, Dropbox, etc.)

Source: _
```

### Example Commands

**Process Local Video:**
```
Source: C:\Users\YourName\Videos\team_meeting.mp4
```

**Process YouTube Video:**
```
Source: https://www.youtube.com/watch?v=dQw4w9WgXcQ
```

**Process Google Drive Link:**
```
Source: https://drive.google.com/file/d/YOUR_FILE_ID/view?usp=sharing
```

---

## ğŸ“š Detailed Usage

### Processing Steps Explained

#### 1ï¸âƒ£ **Video Download/Loading** (5-30 seconds)
- Validates input source
- Downloads YouTube videos or loads local files
- Verifies video integrity

#### 2ï¸âƒ£ **Audio Extraction** (10-60 seconds)
- Extracts WAV audio using FFmpeg
- Maintains original quality for accurate transcription

#### 3ï¸âƒ£ **Transcription** (1-5 minutes for 10-min video)
- Uses OpenAI Whisper for speech-to-text
- Generates timestamped segments
- Creates SRT caption file

#### 4ï¸âƒ£ **Scene & Interaction Detection** (2-10 minutes)
- Analyzes frames for content changes (SSIM threshold: 0.3)
- Detects UI interactions (clicks, transitions)
- Captures screenshots at key moments

#### 5ï¸âƒ£ **Report Generation** (30-90 seconds)
- Compiles comprehensive DOCX/PDF report
- Includes screenshots, timestamps, transcript
- Adds summary and interaction log

#### 6ï¸âƒ£ **Caption Burning** (2-8 minutes)
- Embeds captions into video permanently
- Maintains video quality (H.264 codec)
- Outputs final captioned video

---

## âš™ï¸ Configuration

Edit `config.py` to customize processing:

```python
# Whisper Model Selection
WHISPER_MODEL = "base"  # Options: tiny, base, small, medium, large
# Model size vs accuracy:
# - tiny:   39M params, fastest, 74% accuracy
# - base:   74M params, balanced (DEFAULT)
# - small:  244M params, good accuracy
# - medium: 769M params, high accuracy
# - large:  1550M params, best accuracy (requires GPU)

# Scene Detection Settings
SCENE_CHANGE_THRESHOLD = 0.3  # Lower = more sensitive (0.0-1.0)
FRAME_SAMPLE_RATE = 5  # Process every Nth frame (higher = faster)

# Report Settings
REPORT_FORMAT = "docx"  # Options: "docx", "pdf"

# Caption Styling
CAPTION_FONT_SIZE = 24
CAPTION_FONT_COLOR = "white"
CAPTION_BG_COLOR = "black@0.5"  # Semi-transparent background
CAPTION_POSITION = "bottom"  # Options: "bottom", "top"

# Output Settings
OUTPUT_DIR = "outputs"
KEEP_TEMP_FILES = False  # Set True to keep intermediate files
```

---

## ğŸ“Š Output Examples

### Generated Files Structure
```
outputs/
â”œâ”€â”€ audio/
â”‚   â””â”€â”€ meeting_video.wav          # Extracted audio
â”œâ”€â”€ captions/
â”‚   â””â”€â”€ captions.srt               # Subtitle file
â”œâ”€â”€ frames/
â”‚   â””â”€â”€ meeting_video/
â”‚       â”œâ”€â”€ scene_001_00-02-15.jpg # Scene screenshots
â”‚       â”œâ”€â”€ scene_002_00-05-30.jpg
â”‚       â””â”€â”€ ...
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ meeting_report_20231210_143022.docx  # Comprehensive report
â”œâ”€â”€ final_videos/
â”‚   â””â”€â”€ meeting_video_captioned.mp4  # Final output
â””â”€â”€ temp/
    â””â”€â”€ [temporary processing files]
```

### Sample Report Contents

**Meeting Report Structure:**
1. **Video Information**
   - Title, Duration, Resolution, Source
   
2. **Executive Summary**
   - Key topics discussed
   - Action items identified
   
3. **Scene-by-Scene Breakdown**
   - Timestamp
   - Screenshot
   - Transcript segment
   - Key points
   
4. **Complete Transcript**
   - Full timestamped text
   
5. **UI Interactions Log**
   - Detected clicks/transitions
   - Timestamps and descriptions
   
6. **Appendix**
   - Processing metadata
   - Technical details

---

## ğŸ” Troubleshooting

### Common Issues & Solutions

#### âŒ Error: `FFmpeg not found`
**Solution:**
```bash
# Verify FFmpeg installation
ffmpeg -version

# If not found, reinstall and add to PATH
# Windows: Add C:\ffmpeg\bin to System Environment Variables
# macOS/Linux: Should be automatic with brew/apt
```

#### âŒ Error: `YouTube video download failed`
**Solution:**
```bash
# Update yt-dlp to latest version
pip install --upgrade yt-dlp

# Some videos may be region-restricted or age-restricted
# Try with a different video or use VPN
```

#### âŒ Error: `Out of memory during processing`
**Solutions:**
1. Use smaller Whisper model: `WHISPER_MODEL = "tiny"`
2. Increase frame sample rate: `FRAME_SAMPLE_RATE = 10`
3. Process shorter video segments
4. Close other applications to free RAM

#### âŒ Error: `Google Drive link not working`
**Solution:**
```python
# Ensure the link is:
# 1. Publicly accessible (Anyone with link can view)
# 2. Direct download link format:
# https://drive.google.com/uc?id=FILE_ID&export=download

# Convert preview link to download link:
# From: https://drive.google.com/file/d/FILE_ID/view?usp=sharing
# To:   https://drive.google.com/uc?id=FILE_ID&export=download
```

#### âŒ Error: `Caption burning failed`
**Solution:**
```bash
# Check video codec compatibility
ffmpeg -i input.mp4

# If codec is incompatible, re-encode first:
ffmpeg -i input.mp4 -c:v libx264 -c:a aac output.mp4
```

#### âš ï¸ Warning: `Transcription quality is poor`
**Solutions:**
1. Use larger Whisper model: `WHISPER_MODEL = "medium"`
2. Check audio quality (background noise, multiple speakers)
3. Try preprocessing audio (noise reduction)

---

## ğŸ“ˆ Performance Metrics

### Processing Time Benchmarks
*(Tested on Intel Core i7-10700, 16GB RAM, no GPU)*

| Video Length | Whisper Model | Processing Time | Report Generation | Caption Burning | **Total** |
|--------------|---------------|-----------------|-------------------|-----------------|-----------|
| 5 minutes    | base          | 1m 20s          | 25s               | 1m 15s          | **3m**    |
| 15 minutes   | base          | 3m 45s          | 45s               | 3m 30s          | **8m**    |
| 30 minutes   | base          | 7m 10s          | 1m 15s            | 6m 45s          | **15m**   |
| 60 minutes   | base          | 14m 20s         | 2m 10s            | 13m 15s         | **30m**   |
| 120 minutes  | base          | 28m 40s         | 3m 50s            | 26m 30s         | **59m**   |

### Model Comparison

| Model  | Size   | Speed  | Accuracy | Use Case                    |
|--------|--------|--------|----------|-----------------------------|
| tiny   | 39M    | âš¡âš¡âš¡âš¡  | â­â­      | Quick testing, low resources|
| base   | 74M    | âš¡âš¡âš¡   | â­â­â­    | **Recommended default**     |
| small  | 244M   | âš¡âš¡    | â­â­â­â­  | Better accuracy needed      |
| medium | 769M   | âš¡     | â­â­â­â­â­| High-quality transcription  |
| large  | 1550M  | ğŸŒ     | â­â­â­â­â­| Maximum accuracy (GPU rec.) |

---

## ğŸ“ Project Structure

```
AI-Powered-Automated-Video-Analysis-Pipeline/
â”‚
â”œâ”€â”€ main.py                      # Main entry point
â”œâ”€â”€ config.py                    # Configuration settings
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ modules/                     # Core processing modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ downloader.py            # Video download handler (yt-dlp)
â”‚   â”œâ”€â”€ audio_extractor.py       # Audio extraction (FFmpeg)
â”‚   â”œâ”€â”€ transcription.py         # Whisper transcription
â”‚   â”œâ”€â”€ scene_detection.py       # Computer vision processing
â”‚   â”œâ”€â”€ report_generator.py      # DOCX/PDF generation
â”‚   â”œâ”€â”€ caption_burner.py        # Video caption embedding
â”‚   â””â”€â”€ utils.py                 # Helper functions & logging
â”‚
â”œâ”€â”€ outputs/                     # Generated outputs
â”‚   â”œâ”€â”€ audio/                   # Extracted audio files
â”‚   â”œâ”€â”€ captions/                # SRT subtitle files
â”‚   â”œâ”€â”€ frames/                  # Extracted scene screenshots
â”‚   â”œâ”€â”€ reports/                 # Generated documentation
â”‚   â”œâ”€â”€ final_videos/            # Captioned videos
â”‚   â””â”€â”€ temp/                    # Temporary processing files
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ USER_MANUAL.pdf          # Comprehensive user guide
â”‚   â”œâ”€â”€ INSTALLATION.pdf         # Detailed installation steps
â”‚   â””â”€â”€ API_REFERENCE.md         # Module API documentation
â”‚
â”œâ”€â”€ examples/                    # Sample files
â”‚   â”œâ”€â”€ sample_report.docx       # Example report output
â”‚   â”œâ”€â”€ sample_captions.srt      # Example SRT file
â”‚   â””â”€â”€ demo_screenshots/        # UI screenshots
â”‚
â””â”€â”€ tests/                       # Unit tests (optional)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_downloader.py
    â”œâ”€â”€ test_transcription.py
    â””â”€â”€ test_scene_detection.py
```

---

## ğŸ› ï¸ Technical Stack

### Core Technologies

| Component          | Technology                    | Purpose                           |
|--------------------|-------------------------------|-----------------------------------|
| Video Processing   | **FFmpeg**, **OpenCV**        | Frame extraction, encoding        |
| Speech Recognition | **OpenAI Whisper**            | Audio transcription               |
| Scene Detection    | **SSIM Algorithm**            | Content change identification     |
| Document Generation| **python-docx**, **ReportLab**| Report creation                   |
| Video Download     | **yt-dlp**                    | YouTube video acquisition         |
| Cloud Storage      | **gdown**, **requests**       | Google Drive/Dropbox handling     |

### Python Libraries

```python
# Computer Vision & Video Processing
opencv-python==4.8.1.78          # Image processing, frame analysis
opencv-contrib-python==4.8.1.78  # Additional CV algorithms

# Audio & Speech Processing
openai-whisper==20231117         # Speech-to-text transcription
ffmpeg-python==0.2.0             # Python FFmpeg wrapper

# Document Generation
python-docx==1.1.0               # DOCX report creation
reportlab==4.0.7                 # PDF generation

# Video Downloading
yt-dlp==2023.11.16               # YouTube video download
gdown==4.7.1                     # Google Drive downloads

# Utilities
Pillow==10.1.0                   # Image manipulation
numpy==1.24.3                    # Numerical operations
tqdm==4.66.1                     # Progress bars
requests==2.31.0                 # HTTP requests
```

---

## ğŸ—ºï¸ Roadmap

### âœ… Completed (v1.0)
- [x] Multi-source video input
- [x] Whisper transcription
- [x] Scene detection
- [x] Report generation (DOCX)
- [x] Caption burning
- [x] Single-click automation

### ğŸš§ In Progress (v1.1)
- [ ] PDF report generation (95% complete)
- [ ] Web UI with Streamlit
- [ ] Batch processing mode

### ğŸ”® Planned (v2.0)
- [ ] Speaker diarization (who said what)
- [ ] Multi-language support
- [ ] Keyword extraction & tagging
- [ ] Real-time progress visualization
- [ ] GPU acceleration for Whisper
- [ ] Docker containerization
- [ ] REST API for integration
- [ ] Custom caption styling editor
- [ ] Resume interrupted processing
- [ ] Cloud deployment (AWS/Azure)

### ğŸ’¡ Experimental Ideas
- [ ] Action item detection (AI-powered)
- [ ] Automatic chapter markers
- [ ] Sentiment analysis per segment
- [ ] Integration with Zoom/Teams
- [ ] Mobile app (React Native)

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

### Reporting Issues
1. Check [existing issues](https://github.com/kanishgask/AI-Powered-Automated-Video-Analysis-Pipeline/issues)
2. Create detailed bug reports with:
   - Python version
   - Operating system
   - Error messages and logs
   - Steps to reproduce

### Suggesting Features
1. Open a [feature request](https://github.com/kanishgask/AI-Powered-Automated-Video-Analysis-Pipeline/issues/new)
2. Describe the use case
3. Provide examples if possible

### Pull Requests
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

### Development Setup
```bash
# Clone your fork
git clone https://github.com/YOUR_USERNAME/AI-Powered-Automated-Video-Analysis-Pipeline.git

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Check code style
flake8 modules/
black modules/ --check
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see below for details:

```
MIT License

Copyright (c) 2024 Kanishga SK

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

- **[OpenAI Whisper](https://github.com/openai/whisper)** - State-of-the-art speech recognition
- **[FFmpeg](https://ffmpeg.org/)** - Comprehensive multimedia framework
- **[yt-dlp](https://github.com/yt-dlp/yt-dlp)** - Video downloading utility
- **[OpenCV](https://opencv.org/)** - Computer vision library
- **Python Community** - For excellent documentation and support

---

## ğŸ“ Contact & Support

- **Author**: Kanishga SK
- **GitHub**: [@kanishgask](https://github.com/kanishgask)
- **Project Issues**: [GitHub Issues](https://github.com/kanishgask/AI-Powered-Automated-Video-Analysis-Pipeline/issues)
- **Email**: [your-email@example.com]

---

## ğŸŒŸ Star History


If this project helped you, please consider giving it a â­ï¸!
<img width="1024" height="1024" alt="image" src="https://github.com/user-attachments/assets/3bccc544-c84a-4012-9544-a57f89a43570" />


[![Star History Chart](https://api.star-history.com/svg?repos=kanishgask/AI-Powered-Automated-Video-Analysis-Pipeline&type=Date)](https://star-history.com/#kanishgask/AI-Powered-Automated-Video-Analysis-Pipeline&Date)

---

## ğŸ“¸ Screenshots

### Main Interface
![Main Interface](https://via.placeholder.com/800x500?text=Main+Interface+Screenshot)

### Processing Progress
![Processing](https://via.placeholder.com/800x500?text=Processing+Progress)

### Generated Report
![Report](https://via.placeholder.com/800x500?text=Report+Sample)

### Final Output
![Output](https://via.placeholder.com/800x500?text=Final+Captioned+Video)

---

<div align="center">

**Made with â¤ï¸ for automated meeting documentation**

[â¬† Back to Top](#-ai-powered-meeting-video-analysis--documentation-system)

</div>
